{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clean_census import clean_census_expenditure, clean_census_population, clean_census_poverty\n",
    "from clean_funding import clean_funding\n",
    "from utils_clean_and_analyze import NAICS_SECTOR_LST, CleanedData\n",
    "\n",
    "YEARS = [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "\n",
    "CLEAN_DATA_DIR = \"../data/clean_data/\"\n",
    "RAW_DATA_DIR = \"../data/raw_data/\"\n",
    "\n",
    "def analyze_expenditure_and_funding(years):\n",
    "    \"\"\"\n",
    "    ###\n",
    "\n",
    "    Inputs:\n",
    "        years (lst of str)\n",
    "\n",
    "    Returns:\n",
    "        cleaned_and_combined (dct)\n",
    "    \"\"\"\n",
    "    # Creates and outputs population and poverty data\n",
    "    poverty_df = clean_census_poverty(pd.read_csv(RAW_DATA_DIR + \"us_poverty_by_state.csv\"))\n",
    "    population_df = clean_census_population(pd.read_csv(RAW_DATA_DIR + \"us_census_population.csv\")) \n",
    "\n",
    "    # poverty_df.to_csv(CLEAN_DATA_DIR + \"us_poverty_cleaned.csv\")\n",
    "    # population_df.to_csv(CLEAN_DATA_DIR + \"us_population_cleaned.csv\")\n",
    "\n",
    "    # Clean and combines census data and funding data from each year from 2016 to 2020\n",
    "\n",
    "    cleaned_df_dct = {}\n",
    "\n",
    "    for year in years:\n",
    "        expenditure_csv = RAW_DATA_DIR + year + \"_us_state_finances.csv\" # \"2016_us_state_finances.csv\"\n",
    "        funding_csv = RAW_DATA_DIR + year + \"_us_funding.csv\" # \"2016_us_funding.csv\"\n",
    "\n",
    "        expenditure_df = clean_census_expenditure(pd.read_csv(expenditure_csv))\n",
    "        funding_df, funding_df_by_state, funding_df_within_state  = clean_funding(pd.read_csv(funding_csv), year)\n",
    "    \n",
    "        per_capita_df = pd.DataFrame(columns=[\"Expenditure per Capita (in thousands)\", \"Funding received per Capita (in thousands)\"])\n",
    "        per_capita_df[\"Expenditure per Capita (in thousands)\"] = expenditure_df[\"State Expenditure (in thousands)\"] / population_df[\"Population\"]\n",
    "        per_capita_df[\"Funding received per Capita (in thousands)\"] = funding_df_by_state[\"Total Funding Received\"] / population_df[\"Population\"]\n",
    "\n",
    "        cleaned_df_dct[year] = CleanedData(expenditure_df, per_capita_df, funding_df, funding_df_by_state, funding_df_within_state)\n",
    "\n",
    "        # Outputs files into directory\n",
    "        # funding_df_by_state.to_csv(CLEAN_DATA_DIR + year + \"_cleaned_funding_by_state.csv\")\n",
    "        # funding_df_within_state.to_csv(CLEAN_DATA_DIR + year + \"_cleaned_funding_within_state.csv\")\n",
    "        # funding_df.to_csv(CLEAN_DATA_DIR + year + \"_cleaned_funding_full.csv\")\n",
    "        # expenditure_df.to_csv(CLEAN_DATA_DIR + year + \"_cleaned_expenditure.csv\")\n",
    "        # per_capita_df.to_csv(CLEAN_DATA_DIR + year + \"_per_capita_analysis.csv\")\n",
    "\n",
    "    return cleaned_df_dct\n",
    "\n",
    "\n",
    "def create_funding_time_series_df(year_lst, clean_df_dct):\n",
    "    \"\"\"\n",
    "    ###\n",
    "    \"\"\"\n",
    "    funding_time_series = pd.DataFrame(columns = year_lst)\n",
    "    for year in year_lst:\n",
    "        funding_df = clean_df_dct.get(year).funding_df\n",
    "        us_row_only = funding_df.loc[funding_df.index == \"United States\"]\n",
    "        us_row_only = us_row_only[NAICS_SECTOR_LST]\n",
    "        us_row_only = us_row_only.transpose()\n",
    "        us_row_only.rename(columns = {'United States':'Amount'}, inplace = True)\n",
    "        funding_time_series[year] = (us_row_only[\"Amount\"] / us_row_only[\"Amount\"].sum()) * 100\n",
    "\n",
    "    funding_time_series.index.names = [\"NAICS Category\"]\n",
    "\n",
    "    # Outputs file into directory\n",
    "    funding_time_series.to_csv(CLEAN_DATA_DIR + \"us_funding_time_series.csv\")\n",
    "\n",
    "    return funding_time_series\n",
    "\n",
    "\n",
    "def create_expenditure_time_series_df(year_lst, clean_df_dct):\n",
    "    \"\"\"\n",
    "    ###\n",
    "    \"\"\"\n",
    "    expenditure_time_series = pd.DataFrame(columns = year_lst)\n",
    "    for year in year_lst:\n",
    "        expenditure_df = clean_df_dct.get(year).expenditure_df\n",
    "        us_row_only = expenditure_df.loc[expenditure_df.index == \"United States\"]\n",
    "        sum = int(us_row_only.loc[us_row_only.index == \"United States\", \"State Expenditure (in thousands)\"])\n",
    "        us_row_only = us_row_only[[\"Utilities\", \"Health and Social Services Expenditure\", \"Education Related Expenditure\", \"Public Administration Expenditure\", \"Transportation Expenditure\"]]\n",
    "        us_row_only = us_row_only.transpose()\n",
    "        us_row_only.rename(columns = {'United States':'Amount'}, inplace = True)\n",
    "        us_row_only[\"Sum\"] = sum\n",
    "        expenditure_time_series[year] = (us_row_only[\"Amount\"] / us_row_only[\"Sum\"]) * 100\n",
    "    \n",
    "    expenditure_time_series.index.names = [\"Category\"]\n",
    "\n",
    "    # Outputs file into directory\n",
    "    expenditure_time_series.to_csv(CLEAN_DATA_DIR + \"us_expenditure_time_series.csv\")\n",
    "            \n",
    "    return expenditure_time_series\n",
    "\n",
    "\n",
    "def combine_multiple_years(year_lst, clean_df_dct):\n",
    "    \"\"\"\n",
    "    ###\n",
    "    \"\"\"\n",
    "    funding_df_lst = []\n",
    "    for year in year_lst:\n",
    "        funding_df_lst.append(clean_df_dct.get(year).funding_df_by_state)\n",
    "\n",
    "    combined_df = pd.concat(funding_df_lst)\n",
    "    combined_df = combined_df[combined_df.index != \"United States\"]\n",
    "    combined_df = combined_df.sort_values([\"State\", \"Year\"])\n",
    "\n",
    "    # Outputs file into directory\n",
    "    combined_df.to_csv(CLEAN_DATA_DIR + \"all_years_funding_by_state.csv\")\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poverty_df['State'] = poverty_df['State'].str.strip()\n",
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pop_df['State'] = pop_df['State'].str.strip()\n",
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.index[0:66], inplace=True)\n",
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.index[0:66], inplace=True)\n",
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.index[0:66], inplace=True)\n",
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.index[0:66], inplace=True)\n",
      "/home/foosuonchuang/capp30122/30122-project-cappy-funding/clean_and_analyze/clean_census.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(df.index[0:66], inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Years'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m test_dct \u001b[39m=\u001b[39m analyze_expenditure_and_funding(TEST_YEARS)\n\u001b[1;32m      4\u001b[0m \u001b[39m# create_funding_time_series_df(TEST_YEARS, test_dct)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# create_expenditure_time_series_df(TEST_YEARS, test_dct)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m combine_multiple_years(TEST_YEARS, test_dct)\n",
      "Cell \u001b[0;32mIn[15], line 109\u001b[0m, in \u001b[0;36mcombine_multiple_years\u001b[0;34m(year_lst, clean_df_dct)\u001b[0m\n\u001b[1;32m    107\u001b[0m combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(funding_df_lst)\n\u001b[1;32m    108\u001b[0m combined_df \u001b[39m=\u001b[39m combined_df[combined_df\u001b[39m.\u001b[39mindex \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUnited States\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 109\u001b[0m combined_df \u001b[39m=\u001b[39m combined_df\u001b[39m.\u001b[39;49msort_values([\u001b[39m\"\u001b[39;49m\u001b[39mState\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mYears\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    111\u001b[0m \u001b[39m# Outputs file into directory\u001b[39;00m\n\u001b[1;32m    112\u001b[0m combined_df\u001b[39m.\u001b[39mto_csv(CLEAN_DATA_DIR \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall_years_funding_by_state.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:6891\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   6886\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of ascending (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ascending)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   6887\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m != length of by (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(by)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6888\u001b[0m     )\n\u001b[1;32m   6889\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(by) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 6891\u001b[0m     keys \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_label_or_level_values(x, axis\u001b[39m=\u001b[39maxis) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m by]\n\u001b[1;32m   6893\u001b[0m     \u001b[39m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[1;32m   6894\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6895\u001b[0m         \u001b[39m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[1;32m   6896\u001b[0m         \u001b[39m# expected List[ndarray]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:6891\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   6886\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of ascending (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ascending)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   6887\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m != length of by (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(by)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6888\u001b[0m     )\n\u001b[1;32m   6889\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(by) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 6891\u001b[0m     keys \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(x, axis\u001b[39m=\u001b[39;49maxis) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m by]\n\u001b[1;32m   6893\u001b[0m     \u001b[39m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[1;32m   6894\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6895\u001b[0m         \u001b[39m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[1;32m   6896\u001b[0m         \u001b[39m# expected List[ndarray]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Years'"
     ]
    }
   ],
   "source": [
    "TEST_YEARS = [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "\n",
    "test_dct = analyze_expenditure_and_funding(TEST_YEARS)\n",
    "# create_funding_time_series_df(TEST_YEARS, test_dct)\n",
    "# create_expenditure_time_series_df(TEST_YEARS, test_dct)\n",
    "combine_multiple_years(TEST_YEARS, test_dct)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
